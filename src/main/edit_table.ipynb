{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "from unittest import main\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort news by date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "with open('../../Data/News/news-2019-2020.csv', mode=\"r\", encoding=\"ISO-8859-1\") as rf:\n",
    "    reader = csv.reader(rf)\n",
    "    #skip header \n",
    "    next(reader)\n",
    "    with open(\"../../Data/news_sort.csv\", mode=\"w\", encoding=\"ISO-8859-1\") as wf:\n",
    "        writer = csv.writer(wf)\n",
    "        writer.writerow(['Published_date', 'Headline', 'link'])\n",
    "        # change the format \n",
    "        for line in reader:\n",
    "            dateTime = line[0].split() # Thu, 02 Jan 2020 08:00:00 GMT\n",
    "            datetimeformat = dateTime[3] + \"-\" + dateTime[2] + \"-\" + dateTime[1] + \" \" + dateTime[4] #2020-Jan-02 08:00:00\n",
    "            datetime64format = pd.to_datetime(datetimeformat)\n",
    "            writer.writerow([datetime64format, line[1], line[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/News/news2019-2021.csv')\n",
    "df = df.sort_values(by=\"Published_date\")\n",
    "df.to_csv('../../Data/News/news2019-2021-2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove news name from headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuji\\Desktop\\yxf965\\venv\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "def remove_name(str):\n",
    "    list = str.split('-')\n",
    "    str = '-'.join(list[:-1])      \n",
    "    return str\n",
    "\n",
    "def remove_specialcha(str):\n",
    "    list = str.split('â€“')\n",
    "    if len(list) >= 2:\n",
    "        str = '-'.join(list[:-1])\n",
    "    else:\n",
    "        str = list[0]     \n",
    "    return str\n",
    "\n",
    "df = pd.read_csv('../../Data/News/news2019-2021.csv')\n",
    "df['Headline'] = df['Headline'].apply(remove_name).apply(remove_specialcha)\n",
    "df = df.drop('link', 1)\n",
    "df.to_csv('../../Data/News/news2019-2021.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count news per day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sort_values() got an unexpected keyword argument 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13424\\4144126125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Published_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreformatdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Published_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Published_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../Data/newsCount_2019-2021.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yuji\\Desktop\\yxf965\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sort_values() got an unexpected keyword argument 'by'"
     ]
    }
   ],
   "source": [
    "def reformatdate(df):\n",
    "    newformat = []\n",
    "    for index in df:\n",
    "        newformat.append(pd.to_datetime(index).strftime('%y/%m/%d')) #%d-%m-%y\n",
    "    return newformat\n",
    "\n",
    "df = pd.read_csv('../../Data/Sentiment/combine_2019-2021.csv')\n",
    "df['Published_date'] = reformatdate(df['Published_date'])\n",
    "lst = df['Published_date'].value_counts(sort=False)\n",
    "a = pd.DataFrame(lst)\n",
    "a.to_csv('../../Data/newsCount_2019-2021.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/newsCount_2019-2021.csv')\n",
    "df.sort_values(by='Date',  inplace=True)\n",
    "df.to_csv('../../Data/newsCount_2019-2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort crpto data by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Bitcoin Historical Data.csv')\n",
    "for row in df.iterrows():\n",
    "    dateTime = row[1][0].split() # Aug 24, 2021\n",
    "    dateTime[1].replace(',', '')\n",
    "    datetimeformat = dateTime[2] + \"-\" + dateTime[0] + \"-\" + dateTime[1] #2021-Aug-24\n",
    "    row[1][0] = pd.to_datetime(datetimeformat, unit='D')\n",
    "    \n",
    "df.sort_values(by='Date',  inplace=True)\n",
    "df.to_csv('Data/crypto.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- delate time from date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removetime(str):\n",
    "    return  ''.join(str.split()[:-1])  \n",
    "\n",
    "df = pd.read_csv('final_table.csv', encoding = \"ISO-8859-1\")\n",
    "df['Published_date'] = df['Published_date'].apply(removetime)\n",
    "df.to_csv('remove_time.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count parametar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstday = pd.to_datetime('2019-01-01')\n",
    "lst = []\n",
    "# read files\n",
    "with open('remove_time.csv', mode=\"r\", encoding=\"ISO-8859-1\") as rf:\n",
    "    reader = csv.reader(rf)\n",
    "    next(reader)    #skip title\n",
    "    # change the format \n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for line in reader:\n",
    "        date_row = line[1]\n",
    "        if pd.to_datetime(date_row) == firstday:\n",
    "            if line[7] == 'NEGATIVE':\n",
    "                negative = negative + 1 \n",
    "            if line[7] == 'POSITIVE':\n",
    "                positive = positive + 1\n",
    "        else:\n",
    "            if(positive - negative) >= 0:\n",
    "                lst.append(\"POSITIVE\")\n",
    "            else:\n",
    "                lst.append(\"NEGATIVE\")\n",
    "            positive = 0\n",
    "            negative = 0\n",
    "            firstday = firstday + pd.Timedelta(days=1)\n",
    "    if(positive - negative) >= 0:\n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)   \n",
    "df = pd.read_csv('../../Data/Bitcoin_2019_2020.csv', encoding = \"ISO-8859-1\")\n",
    "df[\"SENTIMENTAL\"] = lst\n",
    "df.to_csv('../../Data/Bitcoin_2019_2020.csv', encoding = \"ISO-8859-1\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare vader and flair result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../../Data/Sentiment/combine_2019-2021.csv')\n",
    "combine_sentiment = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Sentiment_Flair'] == \"NEGATIVE\" and row['Sentiment_Vader'] == \"POSITIVE\":\n",
    "        combine_sentiment.append(\"NEUTRAL\")\n",
    "    elif row['Sentiment_Flair'] == \"NEGATIVE\":\n",
    "        combine_sentiment.append(\"NEGATIVE\")\n",
    "    elif row['Sentiment_Vader'] == \"POSITIVE\":\n",
    "        combine_sentiment.append(\"POSITIVE\")\n",
    "    else:\n",
    "         combine_sentiment.append(\"NEUTRAL\")\n",
    "\n",
    "df['combine_sentiment_N'] = combine_sentiment\n",
    "df.to_csv('../../Data/Sentiment/combine_2019-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794258373205742\n"
     ]
    }
   ],
   "source": [
    "df1= pd.read_csv('../../Data/Training/news_val_2021Jan_noN.csv')\n",
    "i = 0\n",
    "for index, row in df1.iterrows():\n",
    "    if row['Sentiment'] == row['combine_sentiment']:\n",
    "        i  = i + 1\n",
    "\n",
    "accuracy = i / 209\n",
    "        \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpolarity(df):\n",
    "    polarity = []\n",
    "    for index in df:\n",
    "        if index =='POSITIVE':\n",
    "            polarity.append(1)\n",
    "        elif index == 'NEGATIVE':\n",
    "            polarity.append(-1)\n",
    "        else:\n",
    "            polarity.append(0)\n",
    "    return polarity\n",
    "\n",
    "def reformatdate(df):\n",
    "    newformat = []\n",
    "    for index in df:\n",
    "        newformat.append(pd.to_datetime(index).strftime('%y/%m/%d')) #%d-%m-%y\n",
    "    return newformat\n",
    "\n",
    "#get every day avarage sentiment\n",
    "df1 = pd.read_csv('../../Data/Sentiment/combine_2019-2021.csv')\n",
    "df2 = pd.read_csv('../../Data/newsCount_2019-2021.csv')\n",
    "df1['final'] = getpolarity(df1['combine_sentiment_N'])\n",
    "df1['Published_date'] = reformatdate(df['Published_date'])\n",
    "lst= df1.groupby(['Published_date']).sum()['final']\n",
    "lst.to_csv('../../Data/Sentiment/senti_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../../Data/TestData_2019_2021.csv')\n",
    "nextday = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['change in next day (%)'] < 0:\n",
    "        nextday.append(\"NEGATIVE\")\n",
    "    else :\n",
    "        nextday.append(\"POSITIVE\")\n",
    "\n",
    "df['nextDay_prediction'] = nextday\n",
    "df.to_csv('../../Data/TestData_2019_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aadae092c2ccce02241903eb00013032cfcda01a6700d12e3ae101f1192645be"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
